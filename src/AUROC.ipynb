{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEVICE ###\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model = torch.load(os.path.join(\"./\",\"224_2-Copy1.pkl\"))\n",
    "base_model = base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.join(\"../\",\"data\",\"ntu_final_data\")\n",
    "\n",
    "train_file = pd.read_csv(os.path.join(root_dir,\"medical_images\",\"train.csv\"))\n",
    "label_data = []\n",
    "unlabel_data = []\n",
    "for i in train_file.index:\n",
    "    if type(train_file.loc[i][\"Labels\"]) != str:\n",
    "        if math.isnan(train_file.loc[i][\"Labels\"]):\n",
    "            pass\n",
    "            '''\n",
    "            unlabel_data.append( [ train_file.loc[i][\"Image Index\"] ])\n",
    "            '''\n",
    "    else:\n",
    "        p = [train_file.loc[i][\"Image Index\"], train_file.loc[i][\"Labels\"]]\n",
    "        label_data.append(p)\n",
    "        \n",
    "        \n",
    "img_dirs = os.path.join(root_dir,\"medical_images\",\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_RGB(data_list, transform=None, normalize=None):\n",
    "    part_data = []\n",
    "    part_label = []\n",
    "    print(len(data_list))\n",
    "    for i, pair in enumerate(data_list):\n",
    "        print(i,end='\\r')\n",
    "        img = Image.open(os.path.join(img_dirs, pair[0]))\n",
    "        if transform != None:\n",
    "            img = img.convert(mode=\"RGB\")\n",
    "            img = transform(img)\n",
    "            img = np.array(img)/255\n",
    "            img = np.transpose(img, axes=[2,0,1])\n",
    "        else:\n",
    "            img = img.convert(mode=\"RGB\")\n",
    "            img = img.resize((224,224))\n",
    "            img = np.array(img) / 255\n",
    "            img = np.transpose(img, axes=[2,0,1])\n",
    "        label = pair[1].split()\n",
    "        label = np.array([int(c) for c in label])\n",
    "        part_label.append(label)\n",
    "        part_data.append(img)\n",
    "\n",
    "    batch = 4\n",
    "    label_data_x = torch.Tensor(part_data)\n",
    "    label_data_y = torch.Tensor(part_label)\n",
    "    label_dataset = torch.utils.data.TensorDataset(label_data_x, label_data_y)\n",
    "    label_dataloader = torch.utils.data.DataLoader(dataset = label_dataset,\n",
    "                                                   batch_size =batch,\n",
    "                                                   shuffle = False,\n",
    "                                                   num_workers = 1 )\n",
    "    del part_data, part_label\n",
    "    return label_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_L_512(data_list):\n",
    "    part_data = []\n",
    "    part_label=[]\n",
    "    print(len(data_list))\n",
    "    for i, name in enumerate(data_list):\n",
    "        print(i,end='\\r')\n",
    "        img = Image.open(os.path.join(img_dirs, name[0]))\n",
    "        img = img.convert(mode=\"L\")\n",
    "        img = img.resize((512,512))\n",
    "        img = np.array(img)\n",
    "        img = np.expand_dims(img, axis=0) / 255\n",
    "        label = name[1].split()\n",
    "        label = np.array([int(c) for c in label])\n",
    "        part_label.append(label)\n",
    "        part_data.append(img)\n",
    "\n",
    "    batch = 4\n",
    "    label_data_x = torch.Tensor(part_data)\n",
    "    label_data_y = torch.Tensor(part_label)\n",
    "    label_dataset = torch.utils.data.TensorDataset(label_data_x, label_data_y)\n",
    "    label_dataloader = torch.utils.data.DataLoader(dataset = label_dataset,\n",
    "                                                   batch_size =batch,\n",
    "                                                   shuffle = False,\n",
    "                                                   num_workers = 1 )\n",
    "    del part_data\n",
    "    return label_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "val loss:  0.18648454277217388\n",
      "val acc:  0.9485000000000005\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = get_dataloader_RGB(label_data[:len(label_data)//10])\n",
    "val_loss = 0\n",
    "val_acc = 0\n",
    "criterion = torch.nn.BCELoss()\n",
    "ans_list = []\n",
    "label_list = []\n",
    "for b_num, (data, label) in enumerate(val_dataloader):\n",
    "    print(\"Batch: \", b_num, end='\\r')\n",
    "    data = data.to(device)\n",
    "    label = label.to(device)\n",
    "    pred = base_model.output_act( base_model(data) )\n",
    "    loss = criterion(pred,label)\n",
    "    val_loss += loss.item()\n",
    "    val_acc += torch.sum(torch.eq((pred>0.5), label.byte())).item()/14\n",
    "    for one_row in pred.cpu().data.numpy():\n",
    "        ans_list.append(one_row)\n",
    "    for one_row in label.cpu().data.numpy():\n",
    "        label_list.append(one_row)\n",
    "print(\"val loss: \",4*val_loss/ (len(label_data)//10) )\n",
    "print(\"val acc: \",val_acc/(len(label_data)//10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6092768826061293"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sklearn.metrics.roc_auc_score(np.array(label_list),np.array(ans_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "val loss:  0.2047331990227103\n",
      "val acc:  0.9485000000000005\n"
     ]
    }
   ],
   "source": [
    "# for 512x512 model\n",
    "val_dataloader = get_dataloader_L_512(label_data[:len(label_data)//10])\n",
    "val_loss = 0\n",
    "val_acc = 0\n",
    "criterion = torch.nn.BCELoss()\n",
    "ans_list = []\n",
    "label_list = []\n",
    "for b_num, (data, label) in enumerate(val_dataloader):\n",
    "    print(\"Batch: \", b_num, end='\\r')\n",
    "    data = data.to(device)\n",
    "    label = label.to(device)\n",
    "    pred = base_model.output_act( base_model( base_model.pre_conv(data) )  )\n",
    "    loss = criterion(pred,label)\n",
    "    val_loss += loss.item()\n",
    "    val_acc += torch.sum(torch.eq((pred>0.5), label.byte())).item()/14\n",
    "    for one_row in pred.cpu().data.numpy():\n",
    "        ans_list.append(one_row)\n",
    "    for one_row in label.cpu().data.numpy():\n",
    "        label_list.append(one_row)\n",
    "print(\"val loss: \",4*val_loss/ (len(label_data)//10) )\n",
    "print(\"val acc: \",val_acc/(len(label_data)//10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
